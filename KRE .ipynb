{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e70b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import wikipediaapi\n",
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import PromptTemplate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac91877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv('HUGGINGFACE_API_KEY')\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a340d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soft\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "user_agent = 'MyWikipediaApp/1.0 (myemail@example.com)'\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent, 'en')\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device= device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2', token = hf_token)\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2', token = hf_token).to(device)\n",
    "\n",
    "# FAISS index setup\n",
    "index = faiss.IndexFlatL2(384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3960d59",
   "metadata": {},
   "source": [
    "# Read Wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a8d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikipedia_page(link):\n",
    "    page_name = link.split(\"/\")[-1]\n",
    "    page = wiki_wiki.page(page_name)\n",
    "    if not page.exists():\n",
    "        return None, None\n",
    "    return page.title, page.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "276a6f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pakistan\n",
      "Pakistan, officially the Islamic Republic of Pakistan, is a country in South Asia. It is the fifth-most populous country\n"
     ]
    }
   ],
   "source": [
    "title, text = fetch_wikipedia_page(\"https://en.wikipedia.org/wiki/Pakistan\")\n",
    "\n",
    "print(title)\n",
    "print(text[:120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bcae6",
   "metadata": {},
   "source": [
    "# Split data to create chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381df016",
   "metadata": {},
   "source": [
    "# Summarize the wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b56a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=3500):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "def summarize_full_text(text, chunk_size=3500):\n",
    "    text_chunks = chunk_text(text, chunk_size=chunk_size)\n",
    "    \n",
    "    summaries = []\n",
    "    for chunk in text_chunks:\n",
    "        print(\"Writing Summary.......\")\n",
    "        summary = summarizer(chunk, max_length=30, min_length =10, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "\n",
    "    final_summary = \" \".join(summaries)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332573bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Pakistan:\n",
      "Pakistan, officially the Islamic Republic of Pakistan, is a country in South Asia. It is the fifth-most populous country, with a Pakistan is both a Persian and Urdu word. It means the land of the Paks, the spiritually pure and clean. The Ind Several Muslim empires ruled the region from the 7th to 11th centuries CE. Sufi missionaries played a pivotal role in converting a majority In 1942, Britain faced considerable strain during World War II, with India directly threatened by Japanese forces. This led to the adoption of the Pakistan was a monarchy within the Commonwealth of Nations from 1947 to 1956. Lord Mountbatten expressed his lack of support and faith in the Pakistan embarked on an ambitious plan to develop its nuclear deterrence capability in 1972. The country's first nuclear power plant was inaugurated in that Pakistan's size is comparable to France and the UK combined. It is located at the crossroads of South Asia, the Middle East, Pakistan has 174 species of mammals, 177 species of reptiles, 22 species of amphibians, 198 species of freshwater fish, 668 species The Prime Minister is typically the leader of the majority rule party or coalition in the National Assembly. Each of the four provinces follows a similar Since independence, Pakistan has aimed to maintain an independent foreign policy. Pakistan's foreign policy and geostrategy focus on the economy, Pakistan's relationship with the United States has been \"on-and-off\" During the Sovietâ€“Afghan War in the 1980s Pakistan and Bangladesh have experienced strained relations, particularly under the Awami League governments led by Sheikh Hasina, driven by her pro-India The armed forces of Pakistan rank sixth globally in personnel size, with about 660,000 on active duty and 291,000 paramilitary personnel as Pakistan's economy ranks 24th globally by purchasing power parity (PPP) and 43rd by nominal GDP. Pakistan ranked 139 out of Pakistan has an estimated 40 million middle class citizens, projected to increase to 100 million by 2050. The unemployment rate among the aged 15 and Pakistan's IT sector is one of the fastest-growing, ranked 110th for ICT development by the World Economic Forum. The sector Pakistan boasts 2567 km of motorways and approximately 263,942 km of highways, which handle 92% of passengers and 96% In 2010, Pakistan ranked 43rd globally in published scientific papers. By May 2020, Pakistan had 82 million internet users, ranking ninth globally Pakistan is a diverse society with estimates suggesting it has between 75 to 85 languages. Urdu and English serve as the official languages, with As of 2012, 12% of Pakistani Muslims self-identify as non-denominational Muslims. The Ahmadis are a minority Civil society in Pakistan is hierarchical, emphasizing local cultural etiquette and traditional Islamic values. Pakistan allocates 2.3% of its GDP to The national poet of Pakistan, Muhammad Iqbal, wrote influential poetry in Urdu and Persian. Notable figures in contemporary Urdu Pakistan has hosted various international events, including Cricket and Hockey World Cups and Asian Games. Squash player Jahangir Khan holds the record\n"
     ]
    }
   ],
   "source": [
    "title, text = fetch_wikipedia_page(\"https://en.wikipedia.org/wiki/Pakistan\")\n",
    "summary = summarize_full_text(text)\n",
    "print(f\"Summary of {title}:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1882ca",
   "metadata": {},
   "source": [
    "# Embeddings for chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c13335f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to embed text\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a84a9ca",
   "metadata": {},
   "source": [
    "# Save Embeddings to FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37803fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FAISS index\n",
    "index = faiss.IndexFlatL2(384)\n",
    "\n",
    "# Function to index content in FAISS\n",
    "def index_content(content):\n",
    "    chunks = chunk_text(content)\n",
    "    vectors = np.array([embed_text(chunk) for chunk in chunks])\n",
    "    index.add(vectors)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9f7d9",
   "metadata": {},
   "source": [
    "# Search FAISS and retrieve similar embeddings for a given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124cec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search content\n",
    "def search(query, chunks, top_k=5):\n",
    "    query_vector = embed_text(query)\n",
    "    D, I = index.search(np.array([query_vector]), top_k)\n",
    "    return [chunks[i] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6cc1f9",
   "metadata": {},
   "source": [
    "# LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff0e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soft\\AppData\\Local\\Temp\\ipykernel_21712\\1659691192.py:3: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(repo_id=repo_id,\n"
     ]
    }
   ],
   "source": [
    "# Set up LLM \n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, \n",
    "                     huggingfacehub_api_token=hf_token)\n",
    "\n",
    "# prompt template \n",
    "prompt_template = \"\"\"Your question: {question}\n",
    "\n",
    "Answer using the given context: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "def generate_answer_llm(query, chunks):\n",
    "    # Search for relevant chunks based on the query\n",
    "    retrieved_chunks = search(query, chunks)\n",
    "\n",
    "    # Combine retrieved chunks for context\n",
    "    context = ' '.join(retrieved_chunks)\n",
    "\n",
    "    # Generate answer using prompt\n",
    "    result = llm(prompt.format(context=context, question=query))\n",
    "\n",
    "    answer = result.strip() or \"Sorry, I don't know.\"\n",
    "\n",
    "    last_period_index = answer.rfind('.')\n",
    "    if last_period_index != -1:\n",
    "        answer = answer[:last_period_index + 1].strip()  \n",
    "    return answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "311cadf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_wikipedia_page(link):\n",
    "    title, content = fetch_wikipedia_page(link)\n",
    "\n",
    "    summary = summarize_full_text(content)\n",
    "    chunks = index_content(content)\n",
    "    return title, summary, chunks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
